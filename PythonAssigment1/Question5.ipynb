{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "1. Use Gutenberg and Web_text data. Find out what are the top 5 words that Shakespeare used but we do not use in currently.\n",
    "2. Take top 50 words from Shakespeare (all 3 books) and top 50 from Web_text (all the records).\n",
    "3. Remove punctuation and stop words.\n",
    "4. Remove the words we still use today, and get the stop words list. Show the top 5 elements. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Take top 50 words from Shakespeare (all 3 books) and top 50 from Web_text (all the records).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import packages\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import webtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file=gutenberg.fileids() #extract fileids in a variable\n",
    "file_web=webtext.fileids() # extract fileids in a variable\n",
    "stopwords_list=stopwords.words('english') # get the list of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shakespeare words are: \n",
      "\n",
      " ['Tragedie', 'Julius', 'Caesar', 'William', 'Shakespeare', 'Actus', 'Primus', 'Scoena', 'Prima', 'Enter', 'Flauius', 'Murellus', 'certaine', 'Commoners', 'ouer', 'Stage', 'Flauius', 'Hence', 'home', 'idle', 'Creatures', 'get', 'home', 'Holiday', 'know', 'Mechanicall', 'ought', 'walke', 'Vpon', 'labouring', 'day', 'without', 'signe', 'Profession', 'Speake', 'Trade', 'art', 'thou', 'Car', 'Sir', 'Carpenter', 'Mur', 'thy', 'Leather', 'Apron', 'thy', 'Rule', 'dost', 'thou', 'thy']\n"
     ]
    }
   ],
   "source": [
    "# Shakespeare words\n",
    "shakespeare_words=[]\n",
    "for book in file:\n",
    "    if book.startswith('shakespeare'): # check if book name starts with shakespeare\n",
    "        for word in gutenberg.words(book):\n",
    "            if word.isalpha(): # check if the word is alphabetic\n",
    "                if word.lower() not in stopwords_list:\n",
    "                    shakespeare_words.append(word)\n",
    "print(\"The Shakespeare words are: \")\n",
    "print('\\n',shakespeare_words[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 50 words from Shakespeare are: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('haue', 406),\n",
       " ('Ham', 337),\n",
       " ('Lord', 293),\n",
       " ('shall', 259),\n",
       " ('thou', 256),\n",
       " ('King', 231),\n",
       " ('Enter', 225),\n",
       " ('Caesar', 192),\n",
       " ('vs', 183),\n",
       " ('thy', 175),\n",
       " ('thee', 174),\n",
       " ('know', 169),\n",
       " ('good', 165),\n",
       " ('Brutus', 162),\n",
       " ('Bru', 153),\n",
       " ('come', 151),\n",
       " ('like', 142),\n",
       " ('would', 142),\n",
       " ('selfe', 139),\n",
       " ('Macb', 137),\n",
       " ('man', 132),\n",
       " ('well', 126),\n",
       " ('vpon', 126),\n",
       " ('let', 122),\n",
       " ('may', 121),\n",
       " ('must', 116),\n",
       " ('hath', 115),\n",
       " ('say', 113),\n",
       " ('st', 110),\n",
       " ('th', 108),\n",
       " ('Cassi', 107),\n",
       " ('Ile', 106),\n",
       " ('yet', 104),\n",
       " ('see', 104),\n",
       " ('time', 103),\n",
       " ('make', 102),\n",
       " ('one', 101),\n",
       " ('heere', 100),\n",
       " ('speake', 100),\n",
       " ('Hamlet', 99),\n",
       " ('Hor', 95),\n",
       " ('Let', 95),\n",
       " ('vp', 91),\n",
       " ('doe', 89),\n",
       " ('Sir', 89),\n",
       " ('men', 87),\n",
       " ('mine', 86),\n",
       " ('Cassius', 85),\n",
       " ('much', 83),\n",
       " ('loue', 81)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 50 Shakespeare words\n",
    "count_shakes={}\n",
    "for word in shakespeare_words: # check in the list of shakespeare words\n",
    "    if word not in count_shakes:\n",
    "        count_shakes[word]=1 \n",
    "    else:\n",
    "        count_shakes[word]+=1\n",
    "sorted_words=sorted(count_shakes.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"The top 50 words from Shakespeare are: \")\n",
    "sorted_top50_shakes=sorted_words[:50] #\n",
    "sorted_top50_shakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_web' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ffaa6f2bf313>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# finding all the webtext words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mwebtext_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_web\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwebtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'file_web' is not defined"
     ]
    }
   ],
   "source": [
    "# finding all the webtext words\n",
    "webtext_words=[]\n",
    "for book in file_web:\n",
    "    for word in webtext.words(book):\n",
    "            if word.isalpha():\n",
    "                if word.lower() not in stopwords_list:\n",
    "                    webtext_words.append(word)\n",
    "print(\"Webtext words are: \") \n",
    "print(webtext_words[:100]) # webtext words not in stopwords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 50 words from WebText are: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Girl', 1755),\n",
       " ('Guy', 1659),\n",
       " ('like', 1580),\n",
       " ('girl', 1200),\n",
       " ('guy', 1086),\n",
       " ('know', 1020),\n",
       " ('get', 785),\n",
       " ('Yeah', 772),\n",
       " ('page', 723),\n",
       " ('Oh', 664),\n",
       " ('one', 642),\n",
       " ('Woman', 640),\n",
       " ('window', 630),\n",
       " ('Firefox', 602),\n",
       " ('cell', 577),\n",
       " ('open', 567),\n",
       " ('Teen', 550),\n",
       " ('man', 543),\n",
       " ('work', 528),\n",
       " ('Chick', 514),\n",
       " ('Man', 511),\n",
       " ('new', 506),\n",
       " ('go', 496),\n",
       " ('bar', 490),\n",
       " ('good', 488),\n",
       " ('think', 478),\n",
       " ('right', 477),\n",
       " ('want', 471),\n",
       " ('menu', 465),\n",
       " ('tab', 458),\n",
       " ('going', 451),\n",
       " ('Firebird', 437),\n",
       " ('boy', 428),\n",
       " ('Well', 416),\n",
       " ('time', 415),\n",
       " ('got', 402),\n",
       " ('really', 392),\n",
       " ('browser', 392),\n",
       " ('back', 388),\n",
       " ('button', 371),\n",
       " ('lady', 364),\n",
       " ('toolbar', 364),\n",
       " ('bookmarks', 352),\n",
       " ('would', 352),\n",
       " ('people', 345),\n",
       " ('woman', 345),\n",
       " ('dialog', 330),\n",
       " ('bookmark', 329),\n",
       " ('see', 328),\n",
       " ('file', 315)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding top 50 webtext words with their frequencies\n",
    "count_web={}\n",
    "for word in webtext_words:\n",
    "        if word not in count_web:\n",
    "            count_web[word]=1\n",
    "        else:\n",
    "            count_web[word]+=1\n",
    "sorted_words=sorted(count_web.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"The top 50 words from WebText are: \")\n",
    "sorted_top50=sorted_words[:50] # top 50 words of Web\n",
    "sorted_top50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1. Use Gutenberg and Web_text data. Find out what are the top 5 words that Shakespeare used but we do not use in currently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['haue', 'Ham', 'Brutus', 'Bru', 'selfe']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding top 5 Shakespeare words we don't use\n",
    "uncommon_words=[]\n",
    "for words in sorted_top50_shakes:\n",
    "    if words[0] not in set(webtext_words): # words not in set of webtext\n",
    "            uncommon_words.append(words[0])\n",
    "uncommon_words[0:5]\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
