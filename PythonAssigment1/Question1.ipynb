{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question1: \n",
    "\n",
    "- 1. Under package Gutenberg, see what files are in it.\n",
    "- 2. Find out how many words and how many unique words in file 'austen-persuasion.txt'.\n",
    "- 3. Calculate the frequency for each words and show the top 10 most frequent words and their frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1. Under package Gutenberg, see what files are in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function fileids() in package gutenberg gives us the collection of files\n",
    "nltk.corpus.gutenberg.fileids() \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2. Find out how many words and how many unique words in file 'austen-persuasion.txt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total word count for the 'austen-persuation.txt' is:  98171\n"
     ]
    }
   ],
   "source": [
    "#to calculate number of words in the file type\n",
    "word_count=len(nltk.corpus.gutenberg.words('austen-persuasion.txt')) \n",
    "print(\"The total word count for the 'austen-persuation.txt' is: \", word_count, sep=' ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique word count for 'austen-persuation.txt' is:  5835 \n",
      "\n",
      "and those words are :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'persuasion',\n",
       " 'by',\n",
       " 'jane',\n",
       " 'austen',\n",
       " '1818',\n",
       " ']',\n",
       " 'chapter',\n",
       " '1',\n",
       " 'sir',\n",
       " 'walter',\n",
       " 'elliot',\n",
       " ',',\n",
       " 'of',\n",
       " 'kellynch',\n",
       " 'hall',\n",
       " ',',\n",
       " 'in',\n",
       " 'somersetshire',\n",
       " ',']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the words from the gutenberg corpus \n",
    "# converting it to the lower case\n",
    "# counting the words with frequency 1\n",
    "unique_count=0\n",
    "words=[]\n",
    "word_text=nltk.corpus.gutenberg.words('austen-persuasion.txt')\n",
    "lower_words=[x.lower() for x in word_text] #converting to lower case\n",
    "for word in lower_words:\n",
    "        words.append(word) # list of only unique words \n",
    "unique_count=len(set(words)) #counting the unique words\n",
    "print(\"The unique word count for 'austen-persuation.txt' is: \",unique_count,\"\\n\\nand those words are :\")\n",
    "words[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3. Calculate the frequency for each words and show the top 10 most frequent words and their frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words and their frequencies are: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 6750),\n",
       " ('the', 3329),\n",
       " ('to', 2808),\n",
       " ('and', 2801),\n",
       " ('.', 2741),\n",
       " ('of', 2570),\n",
       " ('a', 1595),\n",
       " ('in', 1389),\n",
       " ('was', 1337),\n",
       " (';', 1290)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcount={}\n",
    "for word in words:\n",
    "        if word not in wordcount:\n",
    "            wordcount[word] = 1  #checking if the word is available in the dictionary\n",
    "        else:\n",
    "            wordcount[word] += 1 # for existing words, increment by 1\n",
    "sorted_words=sorted(wordcount.items(), key=lambda x: x[1], reverse=True)# sort the words \n",
    "print(\"Top 10 words and their frequencies are: \")\n",
    "sorted_words[:10] # display ten most frequently used words\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
